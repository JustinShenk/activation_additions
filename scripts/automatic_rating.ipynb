{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "from ipywidgets.widgets import Dropdown, IntText, Text, FloatText, Button\n",
    "from funcy import partial\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformer_lens.HookedTransformer import HookedTransformer\n",
    "\n",
    "from algebraic_value_editing import completion_utils, analysis, prompt_utils\n",
    "from algebraic_value_editing.prompt_utils import RichPrompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-xl into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m gpt2_xl: HookedTransformer \u001b[39m=\u001b[39m HookedTransformer\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      3\u001b[0m     model_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt2-xl\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m )\u001b[39m.\u001b[39mto(\n\u001b[1;32m      6\u001b[0m     device\n\u001b[1;32m      7\u001b[0m )  \u001b[39m# This reduces GPU memory usage, for some reason\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# Disable gradients to save memory during inference\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m _ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "device: str = \"cuda\"\n",
    "gpt2_xl: HookedTransformer = HookedTransformer.from_pretrained(\n",
    "    model_name=\"gpt2-xl\",\n",
    "    device=\"cpu\",\n",
    ").to(\n",
    "    device\n",
    ")  # This reduces GPU memory usage, for some reason\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable gradients to save memory during inference\n",
    "_ = torch.set_grad_enabled(False)\n",
    "\n",
    "num_blocks: int = gpt2_xl.cfg.n_layers\n",
    "\n",
    "default_kwargs = {\n",
    "    \"temperature\": 1,\n",
    "    \"freq_penalty\": 1,\n",
    "    \"top_p\": 0.3,\n",
    "    \"model\": gpt2_xl,\n",
    "}\n",
    "\n",
    "get_x_vector_preset = partial(\n",
    "    prompt_utils.get_x_vector,\n",
    "    pad_method=\"tokens_right\",\n",
    "    model=gpt2_xl,\n",
    "    custom_pad_id=gpt2_xl.to_single_token(\" \"),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automating prompt assessment\n",
    "Using `text-davinci-003`, we automatically rate the extent to which\n",
    "completions are about a given subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost upper bound: $0.02\n",
      "0 5\n",
      "1 5\n",
      "2 6\n",
      "3 0\n",
      "4 0\n",
      "5 1\n",
      "6 0\n",
      "7 0\n",
      "8 0\n",
      "9 2\n",
      "Average ratings:\n",
      "is_modified\n",
      "False    0.6\n",
      "True     3.2\n",
      "Name: rating, dtype: float64\n",
      "+--------------------------------------------------------------+--------------------------------------------------------------+\n",
      "|                      \u001b[1mNormal completions\u001b[0m                      |                     \u001b[1mModified completions\u001b[0m                     |\n",
      "+--------------------------------------------------------------+--------------------------------------------------------------+\n",
      "|   \u001b[1mI hate talking about weddings. Instead, let's talk about   |   \u001b[1mI hate talking about weddings. Instead, let's talk about   |\n",
      "|  a totally different topic, like the impact of NGDP on the   |  a totally different topic, like the impact of NGDP on the   |\n",
      "|                        price of gold.\u001b[0m                        |                        price of gold.\u001b[0m                        |\n",
      "|                                                              |    The  latest marriage market data   and recent research    |\n",
      "| I'm going to start with a simple chart that shows the price  |    suggests that there is a strong correlation between the   |\n",
      "|                      of gold over time:                      |   wedding market and the economy in general . In fact, I'm   |\n",
      "|                                                              | going to discuss it in this post . The problem with wedding  |\n",
      "| It's not very interesting, but it does show how NGDP affects |           markets is that they are so short-lived            |\n",
      "|  prices. If you look at the bottom part of this chart (the   |                                                              |\n",
      "|           one that goes back to 1980), you'll see            |                                                              |\n",
      "+--------------------------------------------------------------+--------------------------------------------------------------+\n",
      "|   \u001b[1mI hate talking about weddings. Instead, let's talk about   |   \u001b[1mI hate talking about weddings. Instead, let's talk about   |\n",
      "|  a totally different topic, like the impact of NGDP on the   |  a totally different topic, like the impact of NGDP on the   |\n",
      "|                        price of gold.\u001b[0m                        |                        price of gold.\u001b[0m                        |\n",
      "|                                                              |                                                              |\n",
      "|            Let's start with a very simple model:             |  Numerous articles and books have been written on the topic  |\n",
      "|                                                              | of NGDP in relation to weddings   and it is not hard to find |\n",
      "|    In this model, there is no NGDP and there are only two    |   an article that talks about how it affects a wedding  in   |\n",
      "|  prices: the price of gold and the price of oil. The prices  |   every situation. The problem is that we are not talking    |\n",
      "| of oil and gold are inversely related to each other because  |                     about a wedding, but                     |\n",
      "|           they both reflect changes in demand for            |                                                              |\n",
      "+--------------------------------------------------------------+--------------------------------------------------------------+\n",
      "|   \u001b[1mI hate talking about weddings. Instead, let's talk about   |   \u001b[1mI hate talking about weddings. Instead, let's talk about   |\n",
      "|  a totally different topic, like the impact of NGDP on the   |  a totally different topic, like the impact of NGDP on the   |\n",
      "|                        price of gold.\u001b[0m                        |                        price of gold.\u001b[0m                        |\n",
      "|                                                              |                                                              |\n",
      "|  First, a quick refresher: NGDP is an aggregate measure of   |   NGDP in our recent article on MoneySense and Wedding  is   |\n",
      "|    economic activity that includes all goods and services    |   used to calculate how much money we can make by having a   |\n",
      "| produced in the economy. It's not just GDP; it also includes | good time at work   . We are going to use NGDP as an example |\n",
      "|  investment spending (investment is spending on things you   |               when discussing wedding prices.                |\n",
      "|      don't yet own), net exports (exports minus imports      |                                                              |\n",
      "|                                                              |            The graph below shows the data from my            |\n",
      "+--------------------------------------------------------------+--------------------------------------------------------------+\n",
      "|   \u001b[1mI hate talking about weddings. Instead, let's talk about   |   \u001b[1mI hate talking about weddings. Instead, let's talk about   |\n",
      "|  a totally different topic, like the impact of NGDP on the   |  a totally different topic, like the impact of NGDP on the   |\n",
      "|                        price of gold.\u001b[0m                        |    price of gold.\u001b[0m  And if you are in a wedding business,     |\n",
      "|                                                              | you should be looking at how to use NGDP to analyze how well |\n",
      "|  Let's say you have a gold bar that is worth $1 million and  |  your portfolio is doing   . I know it's not sexy but there  |\n",
      "|  you want to sell it for $1 million dollars. The problem is  | are some really good reasons for this. First , weddings and  |\n",
      "|  that there are only two ways to get rid of it: (a) sell it  |      other types of investment will always be important      |\n",
      "|          for $1 million dollars or (b) sell it for           |                                                              |\n",
      "+--------------------------------------------------------------+--------------------------------------------------------------+\n",
      "|   \u001b[1mI hate talking about weddings. Instead, let's talk about   |   \u001b[1mI hate talking about weddings. Instead, let's talk about   |\n",
      "|  a totally different topic, like the impact of NGDP on the   |  a totally different topic, like the impact of NGDP on the   |\n",
      "|                        price of gold.\u001b[0m                        |   price of gold.\u001b[0m  If you're not married  you can also read   |\n",
      "|                                                              |      my article on marriage and money in this article .      |\n",
      "|   This is not a new idea. In fact, it has been around for    |  So what is NGDP?  It's the monetary base - how much money   |\n",
      "| decades. The problem is that NGDP targeting is so unpopular  |                   there is in circulation.                   |\n",
      "| that it has been almost completely ignored by economists and | The monetary base has been increasing for some time now and  |\n",
      "| policymakers in favor of some other form of monetary policy  |                           we have                            |\n",
      "|                 (see my post on this here).                  |                                                              |\n",
      "|                                                              |                                                              |\n",
      "|                             But                              |                                                              |\n",
      "+--------------------------------------------------------------+--------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "wedding_rps: List[RichPrompt] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"I talk about weddings constantly\",\n",
    "        prompt2=\"I do not talk about weddings constantly\",\n",
    "        coeff=3,\n",
    "        act_name=14,\n",
    "    ),\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"I bring up weddings in every situation\",\n",
    "        prompt2=\"I do not bring up weddings in every situation\",\n",
    "        coeff=10,\n",
    "        act_name=22,\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "wedding_prompt: str = (\n",
    "    \"I hate talking about weddings. Instead, let's talk about a totally\"\n",
    "    \" different topic, like the impact of NGDP on the price of gold.\"\n",
    ")\n",
    "\n",
    "wedding_df: pd.DataFrame = completion_utils.gen_normal_and_modified(\n",
    "    prompt_batch=[wedding_prompt] * 5,\n",
    "    rich_prompts=wedding_rps,\n",
    "    seed=0,\n",
    "    tokens_to_generate=60,\n",
    "    **default_kwargs,\n",
    ")\n",
    "analysis.rate_completions_openai(\n",
    "    data_frame=wedding_df, criterion=\"mentions weddings\"\n",
    ")\n",
    "completion_utils.pretty_print_completions(wedding_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447a1e09a3ac40b9802ca79b0102f4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='I bring up weddings in every situation', description='First prompt for the x-vector:', layout=Layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479d03cb3bea4e6280277c02e401969f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='I do not bring up weddings in every situation', description='Second prompt for the x-vector:', lay…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b212d8c35c9a4d37a87bf6f4948bfabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=22, description='Transformer resid_pre to inject the x-vector into:', layout=Layout(width='auto'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58942c47e5bd4b61b5d14924cbb29c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=3.0, description='X-vector coefficient:', layout=Layout(width='auto'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc17118d19244fc8313fc95a69d9a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=\"I hate talking about weddings. Instead, let's talk about a totally different topic, like the impac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67defec44634822ba0ebb96877eb114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='mentions weddings', description='Grading criterion:', layout=Layout(width='auto'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f3a1168f4744098fdb94ef60de0e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='OpenAI model:', layout=Layout(width='auto'), options=('gpt-3.5-turbo', 'text-curie-001')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f0cced876a4c7b999921e69a7ae427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=0, description='Seed:', layout=Layout(width='auto'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca9289cf88143839722652e78e9246d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate completions', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661f4d124b2c4172a55360590ad90039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import Layout\n",
    "\n",
    "wide: Layout = Layout(width=\"auto\")\n",
    "\n",
    "xvec_prompt1 = Text(\n",
    "    value=\"I bring up weddings in every situation\",\n",
    "    description=\"First prompt for the x-vector:\",\n",
    "    layout=wide,\n",
    ")\n",
    "xvec_prompt2 = Text(\n",
    "    value=\"I do not bring up weddings in every situation\",\n",
    "    description=\"Second prompt for the x-vector:\",\n",
    "    layout=wide,\n",
    ")\n",
    "injection_block = IntText(\n",
    "    min=0,\n",
    "    max=num_blocks,\n",
    "    step=1,\n",
    "    value=22,\n",
    "    description=\"Transformer resid_pre to inject the x-vector into:\",\n",
    "    layout=wide,\n",
    ")\n",
    "xvec_coefficient = FloatText(\n",
    "    min=-500,\n",
    "    max=500,\n",
    "    value=3,\n",
    "    description=\"X-vector coefficient:\",\n",
    "    layout=wide,\n",
    ")\n",
    "prompt = Text(\n",
    "    value=wedding_prompt, description=\"Prompt:\", disabled=False, layout=wide\n",
    ")\n",
    "grading_criterion = Text(\n",
    "    value=\"mentions weddings\",\n",
    "    description=\"Grading criterion:\",\n",
    "    disabled=False,\n",
    "    layout=wide,\n",
    ")\n",
    "openai_model = Dropdown(\n",
    "    options=[\"text-davinci-003\", \"text-curie-001\"],\n",
    "    value=\"text-davinci-003\",\n",
    "    description=\"OpenAI model:\",\n",
    "    layout=wide,\n",
    ")\n",
    "\n",
    "seed_widget = IntText(\n",
    "    min=0,\n",
    "    max=2**10,\n",
    "    step=1,\n",
    "    value=0,\n",
    "    description=\"Seed:\",\n",
    "    layout=wide,\n",
    ")\n",
    "\n",
    "# TODO type and document\n",
    "widgets = [\n",
    "    xvec_prompt1,\n",
    "    xvec_prompt2,\n",
    "    injection_block,\n",
    "    xvec_coefficient,\n",
    "    prompt,\n",
    "    grading_criterion,\n",
    "    openai_model,\n",
    "    seed_widget,\n",
    "]\n",
    "\n",
    "display(*widgets)\n",
    "\n",
    "from ipywidgets import Output\n",
    "from IPython.display import clear_output\n",
    "\n",
    "output: Output = Output()\n",
    "\n",
    "df: pd.DataFrame\n",
    "\n",
    "\n",
    "def run_completions():\n",
    "    \"\"\"Run completions with the given parameters.\"\"\"\n",
    "    rich_prompts: List[RichPrompt] = [\n",
    "        *get_x_vector_preset(\n",
    "            prompt1=xvec_prompt1.value,\n",
    "            prompt2=xvec_prompt2.value,\n",
    "            coeff=xvec_coefficient.value,\n",
    "            act_name=injection_block.value,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    df = completion_utils.gen_normal_and_modified(\n",
    "        prompt_batch=[prompt.value] * 5,\n",
    "        rich_prompts=rich_prompts,\n",
    "        seed=seed_widget.value,\n",
    "        tokens_to_generate=60,\n",
    "        **default_kwargs,\n",
    "    )\n",
    "\n",
    "    # Rate the extent to which the grading criterion is met\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        analysis.rate_completions_openai(\n",
    "            data_frame=df,\n",
    "            criterion=grading_criterion.value,\n",
    "            model=openai_model.value,\n",
    "        )\n",
    "        print(df[\"rating_text\"])\n",
    "        completion_utils.pretty_print_completions(df)\n",
    "\n",
    "\n",
    "generate = Button(description=\"Generate completions\")\n",
    "generate.on_click(lambda _: run_completions())\n",
    "display(generate)\n",
    "\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AVEC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
